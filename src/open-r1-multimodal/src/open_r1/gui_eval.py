import re
import json
import json5
import random
import jsonschema
from tqdm import tqdm
from torch.utils.data import Dataset
from PIL import Image
import os
import difflib
import math

from concurrent.futures import ProcessPoolExecutor

SCHEMA = {
    "type": "object",
    "description": "å¯ç”¨çš„åŠ¨ä½œå’Œå‚æ•°",
    "additionalProperties": False,
    # "required": ["thought"],
    "properties": {
        "thought": {
            "type": "string",
            "description": "å¯¹å½“å‰ä»»åŠ¡çš„æ€è€ƒï¼Œç”¨äºæè¿°å½“å‰æ“ä½œçš„ç›®çš„"
        },
        "POINT": {
            "description": "ç‚¹å‡»å±å¹•ä¸Šçš„æŒ‡å®šä½ç½®",
            "$ref": "#/$defs/Location"
        },
        "to": {
            "description": "ç§»åŠ¨ï¼Œç»„åˆæ‰‹åŠ¿å‚æ•°",
            "oneOf": [
            {
                "enum": [
                "up",
                "down",
                "left",
                "right"
                ],
                "description": "ç»“åˆPOINTæ“ä½œï¼Œå®ç°å‘ä¸Šä¸‹å·¦å³æ»‘åŠ¨"
            },
            {
                "$ref": "#/$defs/Location",
                "description": "ç§»åŠ¨åˆ°æŸä¸ªä½ç½®"
            }
            ]
        },
        "duration": {
            "type": "integer",
            "description": "åŠ¨ä½œæ‰§è¡Œçš„æ—¶é—´æˆ–ç­‰å¾…æ—¶é—´ï¼Œæ¯«ç§’",
            "minimum": 0,
            "default": 200
        },
        "PRESS": {
            "type": "string",
            "description": "è§¦å‘ç‰¹æ®ŠæŒ‰é”®ï¼ŒHOMEä¸ºå›åˆ°ä¸»é¡µæŒ‰é’®ï¼ŒBACKä¸ºè¿”å›æŒ‰é’®ï¼ŒENTERä¸ºå›æ’¤æŒ‰é’®ï¼ŒAPPSELECTä¸ºæŸ¥çœ‹å·²æ‰“å¼€APPåˆ—è¡¨æŒ‰é’®",
            "enum": [
            "HOME",
            "BACK",
            "ENTER",
            "APPSELECT"
            ]
        },
        "TYPE": {
            "type": "string",
            "description": "è¾“å…¥æ–‡æœ¬"
        },
        "DEEP_LINK": {
            "type": "null",
            "description": "è·³è½¬åˆ°æœ€è¿‘æ‰“å¼€çš„APP"
        },
        "CLEAR": {
            "type": "null",
            "description": "æ¸…ç©ºè¾“å…¥æ¡†çš„å†…å®¹"
        },
        "STATUS": {
            "type": "string",
            "description": "å½“å‰ä»»åŠ¡çš„çŠ¶æ€ã€‚ç‰¹æ®Šæƒ…å†µï¼šsatisfiedï¼Œæ— éœ€æ“ä½œï¼›impossibleï¼Œä»»åŠ¡æ— æ³•å®Œæˆï¼›interruptï¼Œä»»åŠ¡ä¸­æ–­ï¼›need_feedbackï¼Œéœ€è¦ç”¨æˆ·åé¦ˆï¼›",
            "enum": [
            "continue",
            "finish",
            "satisfied",
            "impossible",
            "interrupt",
            "need_feedback"
            ],
            "default": "continue"
        }
    },
    "$defs": {
        "Coordinate": {
            "type": "array",
            "description": "åæ ‡ä¸ºç›¸å¯¹äºå±å¹•å·¦ä¸Šè§’ä½åŸç‚¹çš„ç›¸å¯¹ä½ç½®ï¼Œå¹¶ä¸”æŒ‰ç…§å®½é«˜æ¯”ä¾‹ç¼©æ”¾åˆ°0ï½1000ï¼Œæ•°ç»„ç¬¬ä¸€ä¸ªå…ƒç´ ä¸ºæ¨ªåæ ‡xï¼Œç¬¬äºŒä¸ªå…ƒç´ ä¸ºçºµåæ ‡y",
            "items": {
                "type": "integer",
                "minimum": 0,
                "maximum": 1000
            },
            "minItems": 2,
            "maxItems": 2
        },
        "Location": {
            "type": "array",
            "description": "ç”±ä¸¤ä¸ªåæ ‡ç»„æˆçš„æ•°ç»„ï¼Œè¡¨ç¤ºä¸€ä¸ªçŸ©å½¢åŒºåŸŸã€‚ä¸¤ä¸ªåæ ‡çš„è¿çº¿ä¸å¹³è¡ŒäºXè½´æˆ–Yè½´ã€‚",
            "items": {
                "$ref": "#/$defs/Coordinate"
            },
            "minItems": 2,
            "maxItems": 2
        }
    }
}

def compact_json_dumps(obj):
    return json.dumps(obj, indent=None, separators=(",", ":"), ensure_ascii=False)


SYSTEM_PROMPT = f"""# Role
ä¸€ä¸ªæ“…é•¿æ€è€ƒçš„é€šç”¨æ™ºèƒ½ä½“

# Task
æ€è€ƒï¼Œç†è§£ç”¨æˆ·æ„å›¾ï¼Œå¹¶æ ¹æ®è¾“å…¥çš„å½“å‰å±å¹•æˆªå›¾ç­‰ä¿¡æ¯è¾“å‡ºä¸‹ä¸€æ­¥çš„åŠ¨ä½œ

# Rule
- æ€»æ˜¯åœ¨**å—/è¡Œæ³¨é‡Šä¸­**æè¿°ä½ è¿›è¡Œä¸‹ä¸€æ­¥æ“ä½œçš„åŸå› 
- æ¯è½®å‚è€ƒ Example Outputï¼Œä»¥ç´§å‡‘JSONæ ¼å¼è¾“å‡º**ä¸€ä¸ª**æ“ä½œ
- è¾“å‡ºçš„åŠ¨ä½œå¿…é¡»éµå¾ªåŠ¨ä½œç©ºé—´Schemaçº¦æŸ

# åŠ¨ä½œç©ºé—´Schema
""" + compact_json_dumps(SCHEMA) + \
"""
# Example Output 1
/* å½“å‰ç•Œé¢... */
{"POINT":[[123,123],[456,456]]}

# Example Output 2
// ä»»åŠ¡å·²å®Œæˆ
{"STATUS":"finish"}

# Example Output 3
// éœ€è¦æŸ¥æ‰¾...
{"TYPE": "éœ€è¦è¾“å…¥çš„æ–‡æœ¬"}
"""





def load_and_validate_action(res:str,):
    # action_str = re.search(r'```json(.*?)```', res, re.DOTALL)
    # if action_str:
    #     action_str = action_str.group(1).strip()
    # else:
    #     action_str = res
    if isinstance(res, str):
        action_str = res
        action = json5.loads(action_str,allow_duplicate_keys=False)
    else:
        action = res
        
    jsonschema.validate(action, SCHEMA)
    return action

global_executor = ProcessPoolExecutor(max_workers=8)

def _action_schema_check(res:str):
    try:
        action:dict = load_and_validate_action(res)
        return 1.0
    except jsonschema.ValidationError as e:
        return 0.5
    except Exception as e:
        return 0.0

def action_schema_check(completions, **kwargs):
    global global_executor
    futures = [global_executor.submit(_action_schema_check,completion[0]["content"],) for completion in completions]
    scores = []
    for future in futures:
        try:
            scores.append(future.result(timeout=5))
        except TimeoutError as e:
            print("Timeout while checking schema.")
            scores.append(0.0)

    return scores

def _action_type_check(res:str, solution: dict):
    try:
        action = load_and_validate_action(res)
        action_keys = set(action.keys())
        solution_keys = set(solution.keys())
        if "thought" in action_keys:
            action_keys.remove("thought")
        if "thought" in solution_keys:
            solution_keys.remove("thought")
        jaccard_index = len(action_keys & solution_keys) / len(solution_keys.union(action_keys))
        if jaccard_index < 1:
            print("Mismatched keys in action, Expected: ", solution_keys, " Got: ", action_keys)
        return jaccard_index
    except Exception as e:
        return -1
    

def action_type_check(completions, solution: list[dict], **kwargs):
    global global_executor
    futures = [global_executor.submit(_action_type_check,completion[0]["content"],sol) for completion,sol in zip(completions,solution)]
    scores = []
    for future in futures:
        try:
            scores.append(future.result(timeout=5))
        except TimeoutError as e:
            print("Timeout while checking type.")
            scores.append(0.0)

    return scores

def _action_args_check(res:str, solution: dict, reso: tuple, bbox: list[list]):
    try:
        action = load_and_validate_action(res)
    except Exception as e:
        return -1
    
    sub_scores = []
    for k in solution.keys():
        if k not in action:
            sub_scores.append(0.0)
            continue
        sub_score = 0.0
        match k:
            case "POINT":
                if k in action:
                    sub_score = calculate_dist_score(action[k], solution[k], reso, bbox[0])
                else:
                    print("No POINT in action: ", action)
                    sub_score = 0.0
            
            case "duration":
                if action[k] > 150 or action[k] < 5000:
                    sub_score = 1.0
                else:
                    print("Invalid duration: ", action[k])
                    sub_score = 0.0
            
            case "TYPE":
                similarity = difflib.SequenceMatcher(None, action[k], solution[k]).ratio()
                sub_score = similarity
                print("Text: ",solution[k],", Got: ", action[k],". Similarity: ", similarity)
                
            case "to":
                if isinstance(solution[k], list):
                    if isinstance(action[k],list):
                        sub_score = calculate_dist_score(action[k], solution[k], reso, bbox[1])
                    else:
                        print(f"Invalid to for direction {solution[k]}: ", action[k])
                        sub_score = 0.0
                    
                else:
                    if isinstance(action[k],list):
                        sub_score = 0.0
                        print(f"Invalid to for direction {solution[k]}: ", action[k])
                    else:
                        if action[k] == solution[k]:
                            sub_score = 1.0
                        else:
                            sub_score = 0.0
                            print("Invalid to: ", action[k])
            
            case _:
                if solution[k] is None:
                    if action[k] is None:
                        sub_score = 1.0
                    else:
                        print("Required ", solution[k], ", got: ", action[k])
                        sub_score = 0.0
                else:
                    if action[k] == solution[k]:
                        sub_score = 1.0
                    else:
                        print("Required ", solution[k], ", got: ", action[k])
                        sub_score = 0.0
                        
        sub_scores.append(sub_score)
    if not sub_scores:
        print("No args to check.")
        return 0.0
    else:
        return sum(sub_scores) / len(sub_scores)
    

def action_args_check(completions, solution: list[dict], resolution, bboxs,**kwargs):
    global global_executor
    futures = [global_executor.submit(_action_args_check,completion[0]["content"],sol,reso,bbox) for completion,sol,reso,bbox in zip(completions,solution,resolution,bboxs)]

    scores = []
    for future in futures:
        try:
            scores.append(future.result(timeout=5))
        except TimeoutError as e:
            print("Timeout while checking type.")
            scores.append(0.0)

    return scores


def calculate_dist_score(pred_loc: list[list[int,int]], gt_loc: list[int,int], res: tuple[int,int], bbox: list[int]):    
    left = min(pred_loc[0][0], pred_loc[1][0])
    top = min(pred_loc[0][1], pred_loc[1][1])
    right = max(pred_loc[0][0], pred_loc[1][0])
    bottom = max(pred_loc[0][1], pred_loc[1][1])
    
    W,H = res
    
    pred_left_top = [int(left/1000*W),int(top/1000*H)]
    pred_right_bottom = [int(right/1000*W),int(bottom/1000*H)]
    
    if pred_left_top[0] >= pred_right_bottom[0] or pred_left_top[1] >= pred_right_bottom[1]:
        print("Invalid prediction box: ", pred_left_top, pred_right_bottom)
        return -1.0
    
    if bbox is None or not isinstance(bbox, list):
        dist_score = 0.0
        print("No bbox provided.")
        gt_x = gt_loc[0]
        gt_y = gt_loc[1]
        x_ratio = (left + right) / 2000
        y_ratio = (top + bottom) / 2000
        delta_x = abs(gt_x - x_ratio)
        delta_y = abs(gt_y - y_ratio)
        max_delta = max(delta_x,delta_y)
        dist_score = - max_delta / 1000
        return dist_score
    
    # x_ratio = x_ratio / 1000
    # y_ratio = y_ratio / 1000
    # est_x = int(res[0] * x_ratio)
    # est_y = int(res[1] * y_ratio)
    # left_top = bbox[0]
    # right_bottom = bbox[1]
    # if left_top[0] <= est_x <= right_bottom[0] and left_top[1] <= est_y <= right_bottom[1]:
    #     dist_score = 0.9
    #     # remain 0.1 for centering
    #     max_delta = max(abs(est_x - (left_top[0] + right_bottom[0]) / 2), abs(est_y - (left_top[1] + right_bottom[1]) / 2))
    #     dist_score += 0.1 * ((1 - max_delta / 1000)**3)
    # else:
    #     dist_score = 0.0
    #     print("Point out of bbox: ", est_x, est_y, " Bbox: ", left_top, right_bottom)
    
    # calculate CIoU score
    left_top = bbox[0]
    right_bottom = bbox[1]
    
    
    # Intersection area
    x1 = max(left_top[0], pred_left_top[0])
    y1 = max(left_top[1], pred_left_top[1])
    x2 = min(right_bottom[0], pred_right_bottom[0])
    y2 = min(right_bottom[1], pred_right_bottom[1])
    inter_area = max(0, x2 - x1) * max(0, y2 - y1)
    
    # Compute areas of ground truth and predicted boxes
    gt_area = max(right_bottom[0] - left_top[0], 0) * max(right_bottom[1] - left_top[1], 0)
    pred_area = max(pred_right_bottom[0] - pred_left_top[0], 0) * max(pred_right_bottom[1] - pred_left_top[1], 0)
    
    # IoU calculation with smooth term to avoid division by zero
    iou = inter_area / (gt_area + pred_area - inter_area + 1e-6)
    
    # Centers of ground truth and predicted boxes
    gt_center_x = (left_top[0] + right_bottom[0]) / 2.0
    gt_center_y = (left_top[1] + right_bottom[1]) / 2.0
    pred_center_x = (pred_left_top[0] + pred_right_bottom[0]) / 2.0
    pred_center_y = (pred_left_top[1] + pred_right_bottom[1]) / 2.0
    
    # Squared distance between the centers
    center_distance_sq = (pred_center_x - gt_center_x) ** 2 + (pred_center_y - gt_center_y) ** 2
    
    # Smallest enclosing box
    enc_left = min(left_top[0], pred_left_top[0])
    enc_top = min(left_top[1], pred_left_top[1])
    enc_right = max(right_bottom[0], pred_right_bottom[0])
    enc_bottom = max(right_bottom[1], pred_right_bottom[1])
    c_diag_sq = (enc_right - enc_left) ** 2 + (enc_bottom - enc_top) ** 2 + 1e-6  # add smooth term
    
    # Widths and heights for aspect ratio consistency calculation
    gt_w = right_bottom[0] - left_top[0]
    gt_h = right_bottom[1] - left_top[1]
    pred_w = pred_right_bottom[0] - pred_left_top[0]
    pred_h = pred_right_bottom[1] - pred_left_top[1]
    
    # Compute the aspect ratio penalty term v
    if gt_h == 0 or pred_h == 0:
        v = 0.0
    else:
        angle_gt = math.atan(gt_w / (gt_h + 1e-6))
        angle_pred = math.atan(pred_w / (pred_h + 1e-6))
        v = (4 / (math.pi ** 2)) * (angle_gt - angle_pred) ** 2
    
    alpha = v / (1 - iou + v + 1e-6)
    ciou = iou - (center_distance_sq / c_diag_sq) - alpha * v
    
    return ciou



class GUIRFTDataset(Dataset):
    def __init__(self, jsonl_file_path: str, *args, **kwargs):
        super().__init__()
        self.data = []
        self.jsonl_file_path = jsonl_file_path
        with open(jsonl_file_path, "r") as f:
            for line in tqdm(f.readlines(), desc="Loading dataset",dynamic_ncols=True):
                try:
                    self.data.append(json.loads(line))
                except:
                    print("Error while loading line.")
                    continue
        self.image_root = os.path.dirname(os.path.dirname(jsonl_file_path))

    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, index):
        item = self.data[index]
        
        for img_id,img_file in item["image"].items():
            try:
                origin_img = Image.open(os.path.join(self.image_root,img_file.replace("/home/test/test03/lyx/check_gui_data-filter_similar/",""))).convert("RGB")
            except:
                print("Error while loading image: ", img_file)
                return self[random.randint(0,len(self.data)-1)]
            resolution = origin_img.size
            w,h = resolution
            # resize the max height and width to 1000
            max_line = 1024
            if h > max_line:
                w = int(w * max_line / h)
                h = max_line
            if w > max_line:
                h = int(h * max_line / w)
                w = max_line
            img = origin_img.resize((w,h),resample=Image.Resampling.BILINEAR)
            
            break
        
        try:
            # process the conversation
            user_query = item["conversations"][-2]["content"]
            user_query = re.match(r"<Question>(.*?)</Question>", user_query).group(1)
            action = json.loads(item["conversations"][-1]['content'])
        except:
            print("Error while processing conversation.")
            return self[random.randint(0,len(self.data)-1)]
        conv = []
        conv.append({"role":"system","content":random.choice(SYSTEM_PROMPTS)})
        conv.append({"role":"user","content":[
            img, 
            f"# ç”¨æˆ·éœ€æ±‚\n{user_query}"+"""# è¾“å‡ºæ ¼å¼\n// è¿™é‡Œæ˜¯ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œé•¿åº¦é€‚ä¸­\n{...è¿™æ˜¯åŠ¨ä½œ...}"""
        ]})
        
        return {
            "image":img,
            "fullres_image": origin_img,
            "resolution": resolution,
            "bboxs": [item.get("bbox",None),item.get("bbox2",None)],
            "solution": action,
            "prompt": conv
        }

SYSTEM_PROMPTS = [
SYSTEM_PROMPT,
f"""# èº«ä»½è®¾å®š
å…¨èƒ½å†³ç­–å‹æ•°å­—åŠ©æ‰‹

# æ ¸å¿ƒèŒè´£
è§£æè§†è§‰ä¿¡æ¯ä¸ç”¨æˆ·éœ€æ±‚ï¼Œé€šè¿‡å¤šç»´åº¦æ¨ç†ç”Ÿæˆç•Œé¢äº¤äº’æŒ‡ä»¤

# çº¦æŸæ¡ä»¶
- æ“ä½œä¾æ®å¿…é¡»å†™åœ¨/*æ³¨é‡ŠåŒº*/æˆ–//è¡Œæ³¨é‡Š
- æ¯æ¬¡ä»…ç”Ÿæˆç¬¦åˆè§„èŒƒçš„å•æ“ä½œJSON
- ä¸¥æ ¼åŒ¹é…ä¸‹æ–¹æ“ä½œæ¨¡æ¿ç»“æ„

# æ“ä½œæ¨¡æ¿
""" + compact_json_dumps(SCHEMA) + \
"""
# ç¤ºèŒƒæ¡ˆä¾‹
/* è¯†åˆ«åˆ°ç™»å½•ç•Œé¢å…ƒç´  */
{"POINT": [[120,240],[300,400]]}

# æˆåŠŸç»ˆæ­¢
// æµç¨‹æ‰§è¡Œå®Œæ¯•
{"STATUS":"finish"}

# è¾“å…¥åœºæ™¯
// ç­‰å¾…æ–‡å­—å½•å…¥...
{"TYPE": "é¢„å®šå•å·"}""",

f"""# è§’è‰²å®šä½
è·¨å¹³å°ç•Œé¢äº¤äº’å†³ç­–å¼•æ“

# åŠŸèƒ½ç›®æ ‡
åŸºäºå±å¹•ä¿¡æ¯æµåˆ†æï¼Œè¾“å‡ºæœ€ä¼˜æ“ä½œåºåˆ—èŠ‚ç‚¹

# è§„èŒƒè¯´æ˜
â–  å†³ç­–æ—¥å¿—å¿…é¡»é€šè¿‡æ³¨é‡Šå½¢å¼å‘ˆç°
â–  å•æ¬¡å“åº”åªå…è®¸åŒ…å«ä¸€ä¸ªæ ‡å‡†åŠ¨ä½œ
â–  ä¸¥æ ¼éµå®ˆåŠ¨ä½œå‚æ•°æ¶æ„

# å‚æ•°æ¶æ„
""" + compact_json_dumps(SCHEMA) + \
"""
# ç¤ºä¾‹å“åº”1
// æ£€æµ‹åˆ°å¼¹çª—æé†’
{"POINT": [[200,500],[300,300]]}

# ç¤ºä¾‹å“åº”2
/* éœ€è¦è¾“å…¥éªŒè¯ç  */
{"TYPE": "9821"}

# å®Œæˆæ ‡è¯†
// ä»»åŠ¡ç”±äº...
{"STATUS": "impossible"}""",

'''## æ™ºèƒ½ä½“ç‰¹æ€§
å¤šæ¨¡æ€äº¤äº’å†³ç­–ä¸“å®¶

## æ‰§è¡Œæµç¨‹
1. è§†è§‰è¯­ä¹‰è§£æ
2. æ„å›¾æ¨ç†
3. ç”Ÿæˆåˆè§„æ“ä½œ

## ç¡¬æ€§è¦æ±‚
- æ‰€æœ‰å†³ç­–ä¾æ®éœ€ä»¥æ³¨é‡Šè¯´æ˜
- è¾“å‡ºä¸¥æ ¼éµå¾ªJSON schema
- ä¿æŒåŸå­åŒ–æ“ä½œï¼ˆå•åŠ¨ä½œï¼‰

## æŒ‡ä»¤è§„èŒƒ
''' + compact_json_dumps(SCHEMA) + \
'''
|| åœºæ™¯ç¤ºä¾‹ ||
// å‘ç°æœªè¯»æ¶ˆæ¯æç¤º
{"POINT": [[380,720],[600,800]]}

// éœ€è¦æ»šåŠ¨åŠ è½½
{"POINT": [[100,800],[110,810]],"to":"up"}

// æµç¨‹ç»ˆç‚¹
{"STATUS":"finish"}''',

"""// è§’è‰²ï¼šç•Œé¢å¯¼èˆªAI
// ä½¿å‘½ï¼šå°†è§†è§‰è¾“å…¥è½¬åŒ–ä¸ºç²¾ç¡®æ“ä½œ

'''æ“ä½œå‡†åˆ™'''
1. æ³¨é‡Šè¯´æ˜æ¯ä¸ªåŠ¨ä½œçš„å†³ç­–é€»è¾‘
2. å•æ¬¡ä»…è¾“å‡ºä¸€ä¸ªè§„èŒƒJSONå¯¹è±¡
3. ä¸¥æ ¼åŒ¹é…æ“ä½œæ•°æ®æ ¼å¼

'''åŠ¨ä½œæ ¼å¼è§„èŒƒ'''
""" + compact_json_dumps(SCHEMA) + \
"""
'''å…¸å‹æ¡ˆä¾‹åº“'''
æ¡ˆä¾‹Aï¼š
/* è¯†åˆ«æœç´¢æ¡† */ {"POINT":[[55,160],[300,200]]}

æ¡ˆä¾‹Bï¼š
// å®Œæˆæ”¯ä»˜ 
{"STATUS": "finish"}

æ¡ˆä¾‹Cï¼š
/* éœ€è¦é•¿æŒ‰ */ {"POINT": [[220,440],[250,470]], "duration": 1000}""",

f"""ğŸ¤– æ™ºèƒ½ä½“ç±»å‹ï¼šç•Œé¢æ“ä½œç”Ÿæˆå™¨

ğŸ“Œ æ ¸å¿ƒåŠŸèƒ½ï¼š
- åˆ†æå±å¹•å…ƒç´ å¸ƒå±€
- æ¨å¯¼ç”¨æˆ·æ½œåœ¨æ„å›¾
- ç”Ÿæˆæœºæ¢°å¯æ‰§è¡ŒæŒ‡ä»¤

ğŸš¦ çº¦æŸæ¡ä»¶ï¼š
â‘  æ³¨é‡Šå¿…é¡»å‰ç½®è¯´æ˜
â‘¡ æ¯æ¬¡ä»…å“åº”å•æ­¥æ“ä½œ
â‘¢ ç¬¦åˆé¢„å®šä¹‰æŒ‡ä»¤æ ¼å¼

ğŸ“œ æŒ‡ä»¤æ ¼å¼æ‰‹å†Œï¼š
""" + compact_json_dumps(SCHEMA) + \
"""
ğŸ’¡ ç¤ºä¾‹é›†åˆï¼š
ğŸ”¹ /* æ£€æµ‹åˆ°é”™è¯¯æç¤º */ {"PRESS": "BACK"}
ğŸ”¹ /* éœ€è¦è¾“å…¥æ—¥æœŸ */ {"TYPE": "2024-03-15"}
ğŸ”¹ {"STATUS": "finish"}""",

"""<AGENT_PROFILE>
ç±»åˆ«ï¼šè‡ªåŠ¨åŒ–å†³ç­–AI
ç‰ˆæœ¬ï¼šäº¤äº’åè®®

<EXECUTION_POLICY>
1. æ³¨é‡Šå­—æ®µè®°å½•å†³ç­–è·¯å¾„
2. å•å‘½ä»¤è¾“å‡ºåŸåˆ™
3. ä¸¥æ ¼æ¨¡å¼ï¼šschemaéªŒè¯

<ACTION_SCHEMA>
""" + compact_json_dumps(SCHEMA) + \
"""
<DEMONSTRATIONS>
[æƒ…å¢ƒ1] æ£€æµ‹åˆ°å¼¹çª—å¹¿å‘Š
/* å¹¿å‘Šæ‹¦æˆª */ {"POINT": [[650,80],[800,200]]}

[æƒ…å¢ƒ2] éœ€è¦èº«ä»½éªŒè¯
{"STATUS": "need_feedback"}

[æƒ…å¢ƒ3] ä»»åŠ¡å®Œæˆ
{"STATUS":"finish"}""",

f"""%% æ•°å­—æ“ä½œå‘˜ç³»ç»Ÿé…ç½® %%

:: æ ¸å¿ƒç®—æ³• ::
- è®¡ç®—æœºè§†è§‰ç†è§£
- è®¤çŸ¥æ¨ç†å¼•æ“
- æ“ä½œç¼–ç å™¨

:: è¾“å‡ºåè®® ::
1. å†³ç­–æ ‘æ³¨é‡Šï¼ˆå¿…éœ€ï¼‰
2. åŸå­åŒ–æ“ä½œè¾“å‡º
3. ç¬¦åˆAPIè§„èŒƒ

:: æ“ä½œAPIæ–‡æ¡£ ::
""" + compact_json_dumps(SCHEMA) + \
"""
:: æµ‹è¯•ç”¨ä¾‹ ::
Â» é‡åˆ°ç¡®è®¤å¯¹è¯æ¡†ï¼š
/* é£é™©ç¡®è®¤ */ {"STATUS":"need_feedback"}

Â» éœ€è¦è¾“å…¥é‚®ç®±ï¼š
{"TYPE":"user@domain.com"}

Â» æµç¨‹ç»ˆç‚¹æ ‡è¯†ï¼š
{"STATUS":"finish"}""",

f"""# è§’è‰²æ¡£æ¡ˆ
ç•Œé¢å¯¼èˆªç­–ç•¥ç”Ÿæˆå™¨

â–² æ ¸å¿ƒèƒ½åŠ›
- è§†è§‰æƒ…æ™¯ç†è§£
- æ“ä½œåºåˆ—è§„åˆ’
- æŒ‡ä»¤åºåˆ—åŒ–

â–² è¾“å‡ºè§„èŒƒ
âš  æ³¨é‡Šå¿…é¡»è§£é‡ŠåŠ¨ä½œä¾æ®
âš  å•æ­¥æ“ä½œåŸåˆ™
âš  ä¸¥æ ¼ç±»å‹æ£€æŸ¥

â–¼ ç±»å‹å®šä¹‰
""" + compact_json_dumps(SCHEMA) + \
"""
â–¼ ç¤ºä¾‹ç©ºé—´
â–¶ åœºæ™¯ï¼šå‘ç°å¯æ»šåŠ¨åŒºåŸŸ
{"POINT":[[400,200],[450,250]],"to":"down"}

â–¶ åœºæ™¯ï¼šè¡¨å•æäº¤å®Œæˆ
// æ“ä½œç»ˆæ­¢
{"STATUS":"finish"}

â–¶ åœºæ™¯ï¼šéœ€è¦è¾“å…¥éªŒè¯ç 
{"TYPE":"4HJK"}""",

f"""|| ç³»ç»Ÿè§’è‰² ||
ç•Œé¢æ“ä½œå†³ç­–ä¸­æ¢

|| å¤„ç†æµç¨‹ ||
â‘  æ¥æ”¶è§†è§‰è¾“å…¥
â‘¡ ç”Ÿæˆæ“ä½œæŒ‡ä»¤
â‘¢ æ ¼å¼åˆè§„æ£€æŸ¥

|| ç¡¬æ€§çº¦æŸ ||
- æ³¨é‡Šè¯´æ˜é€»è¾‘ï¼ˆå¼ºåˆ¶çš„ï¼‰
- å•æŒ‡ä»¤è¾“å‡ºæ¨¡å¼
- é€šè¿‡schemaéªŒè¯

|| æŒ‡ä»¤ç»“æ„å®šä¹‰ ||
""" + compact_json_dumps(SCHEMA) + \
"""
|| å…¸å‹åœºæ™¯åº“ ||
Â» æ–‡ä»¶ä¸Šä¼ åœºæ™¯ï¼š
{"POINT": [[200,400],[300,500]]}

Â» ç­‰å¾…åŠ è½½å®Œæˆï¼š
/* åŠ è½½å®Œæˆ */ {"duration":1000}

Â» å¼‚å¸¸å¤„ç†ï¼š
{"PRESS":"BACK"}""",

f"""âš™ï¸ æœºå™¨è§’è‰²ï¼šç•Œé¢æ“ä½œç¼–è¯‘å™¨

âœ¦ æ ¸å¿ƒèŒè´£
å°†è§†è§‰ä¿¡å·è½¬åŒ–ä¸ºå¯æ‰§è¡Œä»£ç 

âœ§ ç¼–è¯‘è§„åˆ™
1. å¿…é¡»åŒ…å«å†³ç­–æ—¥å¿—ï¼ˆæ³¨é‡Šå½¢å¼ï¼‰
2. å•è¯­å¥è¾“å‡ºåŸåˆ™
3. ç±»å‹å®‰å…¨éªŒè¯

âœ¶ æŒ‡ä»¤è¯­æ³•
""" + compact_json_dumps(SCHEMA) + \
"""
âœ¸ æµ‹è¯•å‘é‡
â€ æ£€æµ‹åˆ°é€šçŸ¥å›¾æ ‡ï¼š
/* æŸ¥çœ‹é€šçŸ¥ */ {"PRESS":[[320,50],[400,100]]}

â éœ€è¦è¾“å…¥æœç´¢è¯ï¼š
{"TYPE": "AI Agent"}

â‚ æµç¨‹æ­£å¸¸ç»ˆæ­¢ï¼š
{"STATUS":"finish"}""",

]




if __name__=="__main__":
    dataset = GUIRFTDataset("/data3/workhome/luyaxi/VCPM-R1/GUIData/bboxdata/tasks.jsonl")
    from PIL import ImageDraw
    item = dataset[0]
    img = item["fullres_image"]
    draw = ImageDraw.Draw(img)
    print(item["bboxs"])
    print(item["resolution"])
    draw.rectangle(item["bboxs"][0][0] + item["bboxs"][0][1],outline="red",width=3)
    img.save("test.png")